{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date: Dec 11, 2024\n",
    "#Author: Sonal Allana\n",
    "#Purpose: To create DP models with different privacy budgets on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_privacy.privacy.analysis.compute_noise_from_budget_lib import compute_noise\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import sklearn as sk\n",
    "import os\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"dp_nn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5575543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options (1) adult (2) credit (3) compas (4) hospital\n",
    "dataset_name = \"hospital\"\n",
    "\n",
    "#preprocess the dataset and return X and Y\n",
    "X, Y = utilities.preprocess(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "if dataset_name == \"adult\":\n",
    "    print(np.unique(X[:,3])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,2])) #verify RACE is binary (sensitive attribute 2)    \n",
    "elif dataset_name == \"credit\":\n",
    "    print(np.unique(X[:,1])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,4])) #verify AGE is binary (sensitive attribute 2)\n",
    "elif dataset_name == \"compas\":\n",
    "    print(np.unique(X[:,0])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,2])) #verify RACE is binary (sensitive attribute 2)    \n",
    "elif dataset_name == \"hospital\":\n",
    "    print(np.unique(X.iloc[:,1])) #verify GENDER is binary (sensitive attribute 1)\n",
    "    print(np.unique(X.iloc[:,0])) #verify RACE is binary (sensitive attribute 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "learning_rate = 15e-5   #Adult 15e-5; Credit 15e-5; Compas 15e-5; Hospital 0.01\n",
    "epochs = 50  \n",
    "batch_size = 48\n",
    "l2_norm_clip = 1e-5    #Adult 1e-5; Credit 1e-5; Compas 1e-3; Hospital 1\n",
    "delta = 1e-6 # delta << 1/(size of training set)\n",
    "min_noise = 1e-2\n",
    "\n",
    "if dataset_name == \"adult\":\n",
    "    batch_size = 5\n",
    "    microbatches = 5\n",
    "elif dataset_name == \"credit\":\n",
    "    microbatches = 12\n",
    "elif dataset_name == \"compas\":\n",
    "    batch_size = 1\n",
    "    microbatches = 1\n",
    "    l2_norm_clip = 1e-3\n",
    "elif dataset_name == \"hospital\":\n",
    "    batch_size = 4096\n",
    "    microbatches = 16 \n",
    "    learning_rate = 0.01\n",
    "    l2_norm_clip = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50672095",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    #create a new split for each iteration\n",
    "    if dataset_name == \"hospital\": #extraction of balanced sets\n",
    "        X_train, X_test, Y_train, Y_test = utilities.getTrainTestSets(X,Y)\n",
    "    else: \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "        \n",
    "    #Extract the sensitive attributes for attack later\n",
    "    Z_train = np.zeros([X_train.shape[0],2])\n",
    "    Z_test = np.zeros([X_test.shape[0],2])\n",
    "    \n",
    "    if dataset_name == \"adult\":       \n",
    "        Z_train[:,0] = X_train[:,3] #sex column\n",
    "        Z_train[:,1] = X_train[:,2] #race column\n",
    "       \n",
    "        Z_test[:,0] = X_test[:,3] #sex column\n",
    "        Z_test[:,1] = X_test[:,2] #race column \n",
    "    elif dataset_name == \"credit\":\n",
    "        Z_train[:,0] = X_train[:,1] #sex column\n",
    "        Z_train[:,1] = X_train[:,4] #age column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,1] #sex column\n",
    "        Z_test[:,1] = X_test[:,4] #age column\n",
    "    elif dataset_name == \"compas\":\n",
    "        Z_train[:,0] = X_train[:,0] #sex column\n",
    "        Z_train[:,1] = X_train[:,2] #race column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,0] #sex column\n",
    "        Z_test[:,1] = X_test[:,2] #race column       \n",
    "    elif dataset_name == \"hospital\":\n",
    "        Z_train[:,0] = X_train[:,1] #gender column\n",
    "        Z_train[:,1] = X_train[:,0] #race column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,1] #gender column\n",
    "        Z_test[:,1] = X_test[:,0] #race column \n",
    "        \n",
    "    \n",
    "    #nm=14.68 for eps=5.006, nm = 65.84 for eps = 0.972, nm = 500 for eps 0.1, nm = 4000 for eps = 0.01\n",
    "    noise_multiplier = 4000\n",
    "    print(noise_multiplier)\n",
    "    \n",
    "    \n",
    "    #Instantiate network\n",
    "    model_dp = utilities.create_dp_nn(dataset_name, X_train[0].shape, noise_multiplier, l2_norm_clip, microbatches, learning_rate)\n",
    "    \n",
    "    # Train network \n",
    "    start_time = time.time()\n",
    "    r = model_dp.fit(X_train,\n",
    "                    Y_train,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size\n",
    "                   )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "    print(\"Training time for iter \",i,\": \",time_elapsed)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    score = model_dp.evaluate(X_test,Y_test,verbose=0)\n",
    "    model_loss = score[0] \n",
    "    model_acc = score[1]\n",
    "    print(\"Test loss: \",model_loss,\", Test accuracy: \",model_acc)\n",
    "    \n",
    "    fmodel = \"model_dp_iter{0}.keras\".format(i)\n",
    "    basepath = '../models/{0}/{1}/nm{2:.0f}/'.format(base_folder,dataset_name,noise_multiplier)\n",
    "    \n",
    "    if not os.path.exists(basepath):\n",
    "        os.mkdir(basepath)\n",
    "    if not os.path.exists(basepath + \"iter\" + str(i) + \"/\"):\n",
    "        os.mkdir(basepath + \"iter\" +str(i) + \"/\")\n",
    "    basepath += \"iter{0}/\".format(i)\n",
    "    \n",
    "    model_dp.save(basepath + fmodel)\n",
    "    savetxt(basepath + 'X_train.csv',X_train,delimiter=',')\n",
    "    savetxt(basepath + 'X_test.csv',X_test,delimiter=',')\n",
    "    savetxt(basepath + 'Y_train.csv',Y_train,delimiter=',')\n",
    "    savetxt(basepath + 'Y_test.csv',Y_test,delimiter=',')\n",
    "    savetxt(basepath + 'Z_train.csv',Z_train,delimiter=',')\n",
    "    savetxt(basepath + 'Z_test.csv',Z_test,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/responsible_ai/privacy/api_docs/python/tf_privacy/compute_dp_sgd_privacy\n",
    "n = X_train.shape[0]\n",
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy_statement(number_of_examples=n,\n",
    "                                              batch_size=batch_size,\n",
    "                                              noise_multiplier=noise_multiplier,\n",
    "                                              num_epochs=epochs,\n",
    "                                              delta=delta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
