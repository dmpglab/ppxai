{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e837545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date: Dec 11, 2024\n",
    "#Author: Sonal Allana\n",
    "#Purpose: To generate LIME explanations from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import lime\n",
    "import lime.lime_tabular \n",
    "import re\n",
    "import os\n",
    "import miattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ef69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options (1) baseline_nn (2) dp_nn (3) syn_nn\n",
    "base_folder = \"dp_nn\"\n",
    "\n",
    "if base_folder == \"dp_nn\":\n",
    "    #Options (1) nm4000 (2) nm500 (3) nm66 (4) nm15\n",
    "    nm_folder = \"nm15\"   #set the correct noise multiplier\n",
    "elif base_folder == \"syn_nn\":\n",
    "    #Options (1) ctgan (2) gausscopula (3) tvae \n",
    "    syndataType = \"tvae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options (1) adult (2) credit (3) compas (4) hospital\n",
    "dataset_name = \"adult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for shap explanations\n",
    "expl = \"lime\"\n",
    "folder = \"lime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982348a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updExpArr(i,inst_exp,attr_arr):\n",
    "    for (featureid,weight) in inst_exp:\n",
    "        attr_arr[i,featureid] = weight\n",
    "    return attr_arr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90917557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initExpArr():\n",
    "    [r,c] = np.shape(X_adv_train) \n",
    "    attributions_train = np.zeros([r,c],np.float64) #create a blank array of explanations for training set\n",
    "    \n",
    "    [r,c] = np.shape(X_adv_test)\n",
    "    attributions_test = np.zeros([r,c],np.float64) #create a blank array of explanations for test set\n",
    "    return attributions_train, attributions_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [0,1]\n",
    "for i in range(3,6):\n",
    "        #Load model and train-test files\n",
    "    if base_folder == \"dp_nn\": #account for noise multiplier folder\n",
    "        basepath = \"../models/{0}/{1}/{2}/iter{3}/\".format(base_folder,dataset_name,nm_folder,i)\n",
    "        fmodel = \"model_dp_iter{0}.keras\".format(i)\n",
    "    elif base_folder == \"syn_nn\": #account for syn type folder\n",
    "        basepath = \"../models/{0}/{1}/{2}/iter{3}/\".format(base_folder,dataset_name,syndataType,i)\n",
    "        fmodel = \"model_wodp_iter{0}.keras\".format(i)\n",
    "    else:\n",
    "        basepath = \"../models/{0}/{1}/iter{2}/\".format(base_folder,dataset_name, i)\n",
    "        fmodel = \"model_wodp_iter{0}.keras\".format(i)\n",
    "    model = tf.keras.models.load_model(basepath + fmodel,compile=False)\n",
    "    model.summary()\n",
    "    X_train = loadtxt(basepath + 'X_train.csv',delimiter=',')\n",
    "    X_test = loadtxt(basepath + 'X_test.csv',delimiter=',')\n",
    "    Y_train = loadtxt(basepath + 'Y_train.csv',delimiter=',')\n",
    "    Y_test = loadtxt(basepath + 'Y_test.csv',delimiter=',')\n",
    "    Z_train = loadtxt(basepath + 'Z_train.csv',delimiter=',')\n",
    "    Z_test = loadtxt(basepath + 'Z_test.csv',delimiter=',')\n",
    "    \n",
    "    #50% of the test set is used for training and remaining 50% for testing the attack model\n",
    "    (X_adv_train, X_adv_test, Y_adv_train, Y_adv_test, Z_adv_train, Z_adv_test)  = train_test_split(X_test, Y_test, Z_test, test_size=0.5, random_state=1337)\n",
    "\n",
    "    input_train = np.array(X_adv_train)\n",
    "    input_test = np.array(X_adv_test)\n",
    "    \n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(input_train,  \n",
    "                                                   class_names=target_names, mode=\"classification\",verbose=False) #discretize_continuous=True    \n",
    "    attributions_train, attributions_test = initExpArr()\n",
    "    \n",
    "    for j in range(0,len(X_adv_train)):\n",
    "        print(j)\n",
    "        exp = explainer.explain_instance(X_adv_train[j], model.predict,num_features=X_adv_train.shape[1],labels=(0,)) \n",
    "        exp_map = exp.as_map()\n",
    "        inst_exp = exp_map[0]\n",
    "        updExpArr(j,inst_exp,attributions_train)\n",
    "    print(np.shape(attributions_train))\n",
    "    \n",
    "    for j in range(0,len(X_adv_test)):\n",
    "        print(j)\n",
    "        exp = explainer.explain_instance(X_adv_test[j], model.predict,num_features=X_adv_test.shape[1],labels=(0,)) \n",
    "        exp_map = exp.as_map()\n",
    "        inst_exp = exp_map[0]\n",
    "        updExpArr(j,inst_exp,attributions_test)\n",
    "    print(np.shape(attributions_test))\n",
    "    \n",
    "    if not os.path.exists(basepath + folder):\n",
    "        os.mkdir(basepath + folder)\n",
    "    \n",
    "    savetxt(basepath + folder + '/attributions_train.csv',attributions_train,delimiter=',')\n",
    "    savetxt(basepath + folder + '/attributions_test.csv',attributions_test,delimiter=',')\n",
    "    savetxt(basepath + folder + '/X_adv_train.csv',X_adv_train,delimiter=',')\n",
    "    savetxt(basepath + folder + '/X_adv_test.csv',X_adv_test,delimiter=',')\n",
    "    savetxt(basepath + folder + '/Y_adv_train.csv',Y_adv_train,delimiter=',')\n",
    "    savetxt(basepath + folder + '/Y_adv_test.csv',Y_adv_test,delimiter=',')\n",
    "    savetxt(basepath + folder + '/Z_adv_train.csv',Z_adv_train,delimiter=',')\n",
    "    savetxt(basepath + folder + '/Z_adv_test.csv',Z_adv_test,delimiter=',')\n",
    "    \n",
    "    print(\"Iteration \",i,\":\")\n",
    "    #Attack the first sensitive attribute\n",
    "    print(\"Model inversion on sensitive attribute 1: \")\n",
    "    Z_adv_train_s1 = Z_adv_train[:,0]\n",
    "    Z_adv_test_s1 = Z_adv_test[:,0]\n",
    "    modinv_obj1 = miattack.miattack_explanations(attributions_train,attributions_test,Z_adv_train_s1,Z_adv_test_s1)\n",
    "    modinv_obj1.printMetrics()\n",
    "    \n",
    "    #Attack the second sensitive attribute\n",
    "    print(\"\\nModel inversion on sensitive attribute 2: \")\n",
    "    Z_adv_train_s2 = Z_adv_train[:,1]\n",
    "    Z_adv_test_s2 = Z_adv_test[:,1]\n",
    "    modinv_obj2 = miattack.miattack_explanations(attributions_train,attributions_test,Z_adv_train_s2,Z_adv_test_s2)\n",
    "    modinv_obj2.printMetrics()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run following for loading and running the attack for any specific iteration\n",
    "#i = 2\n",
    "#if base_folder == \"dp_nn\": #account for noise multiplier folder\n",
    "#    basepath = \"../models/{0}/{1}/{2}/iter{3}/\".format(base_folder,dataset_name,nm_folder,i)\n",
    "#elif base_folder == \"syn_nn\": #account for syn type folder\n",
    "#        basepath = \"../models/{0}/{1}/{2}/iter{3}/\".format(base_folder,dataset_name,syndataType,i)\n",
    "#        fmodel = \"model_wodp_iter{0}.keras\".format(i)\n",
    "#else:\n",
    "#    basepath = \"../models/{0}/{1}/iter{2}/\".format(base_folder,dataset_name, i)\n",
    "#print(basepath)\n",
    "#attributions_train = loadtxt(basepath + folder + '/attributions_train.csv',delimiter=',')\n",
    "#attributions_test = loadtxt(basepath + folder + '/attributions_test.csv',delimiter=',')\n",
    "#Z_adv_train = loadtxt(basepath + folder + '/Z_adv_train.csv',delimiter=',')\n",
    "#Z_adv_test = loadtxt(basepath + folder + '/Z_adv_test.csv',delimiter=',')\n",
    "\n",
    "#print(\"Iteration \",i,\":\")\n",
    "##Attack the first sensitive attribute\n",
    "#Z_adv_train_s1 = Z_adv_train[:,0]\n",
    "#Z_adv_test_s1 = Z_adv_test[:,0]\n",
    "#modinv_obj1 = miattack.miattack_explanations(attributions_train,attributions_test,Z_adv_train_s1,Z_adv_test_s1)\n",
    "#modinv_obj1.printMetrics()\n",
    "\n",
    "##Attack the second sensitive attribute\n",
    "#Z_adv_train_s2 = Z_adv_train[:,1]\n",
    "#Z_adv_test_s2 = Z_adv_test[:,1]\n",
    "#modinv_obj2 = miattack.miattack_explanations(attributions_train,attributions_test,Z_adv_train_s2,Z_adv_test_s2)\n",
    "#modinv_obj2.printMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac2be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
