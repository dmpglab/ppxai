{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date: Dec 11, 2024\n",
    "#Author: Sonal Allana\n",
    "#Purpose: To create NN models on each synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import sklearn as sk\n",
    "import os\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"syn_nn\"\n",
    "#Options (1) ctgan (2) gausscopula (3) tvae \n",
    "syndataType = \"gausscopula\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5575543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options (1) adult (2) credit (3) compas (4) hospital\n",
    "dataset_name = \"hospital\"\n",
    "\n",
    "#preprocess the dataset and return X and Ys\n",
    "X, Y = utilities.loadSynDataset(dataset_name, syndataType)\n",
    "#X,Y = utilities.preprocess_diabetes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "print(X)\n",
    "print(np.unique(Y))\n",
    "\n",
    "if dataset_name == \"adult\":\n",
    "    print(np.unique(X[:,3])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,2])) #verify RACE is binary (sensitive attribute 2)    \n",
    "elif dataset_name == \"credit\":\n",
    "    print(np.unique(X[:,1])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,4])) #verify AGE is binary (sensitive attribute 2)\n",
    "elif dataset_name == \"compas\":\n",
    "    print(np.unique(X[:,0])) #verify SEX is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,2])) #verify RACE is binary (sensitive attribute 2)    \n",
    "elif dataset_name == \"hospital\":\n",
    "    print(np.unique(X[:,1])) #verify GENDER is binary (sensitive attribute 1)\n",
    "    print(np.unique(X[:,0])) #verify RACE is binary (sensitive attribute 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "learning_rate = 15e-5   #lr = 15e-1  gives good result for eps 0.3\n",
    "epochs = 50\n",
    "batch_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50672095",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    #create a new split for each iteration\n",
    "    if dataset_name == \"hospital\":\n",
    "        X_train, X_test, Y_train, Y_test = utilities.getTrainTestSets(X,Y)\n",
    "    else: \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "    #For synthetic data, train set should be synthetic and test set should be original (non-synthetic)\n",
    "    bpath = '../models/baseline_nn/{0}/iter{1}/'.format(dataset_name,i) \n",
    "    X_test = loadtxt(bpath + 'X_test.csv',delimiter=',')\n",
    "    Y_test = loadtxt(bpath + 'Y_test.csv',delimiter=',')\n",
    "\n",
    "    #Extract the sensitive attributes for attack later\n",
    "    Z_train = np.zeros([X_train.shape[0],2])\n",
    "    Z_test = np.zeros([X_test.shape[0],2])\n",
    "    \n",
    "    if dataset_name == \"adult\":       \n",
    "        Z_train[:,0] = X_train[:,3] #sex column\n",
    "        Z_train[:,1] = X_train[:,2] #race column\n",
    "       \n",
    "        Z_test[:,0] = X_test[:,3] #sex column\n",
    "        Z_test[:,1] = X_test[:,2] #race column \n",
    "    elif dataset_name == \"credit\":\n",
    "        Z_train[:,0] = X_train[:,1] #sex column\n",
    "        Z_train[:,1] = X_train[:,4] #age column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,1] #sex column\n",
    "        Z_test[:,1] = X_test[:,4] #age column\n",
    "    elif dataset_name == \"compas\":\n",
    "        Z_train[:,0] = X_train[:,0] #sex column\n",
    "        Z_train[:,1] = X_train[:,2] #race column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,0] #sex column\n",
    "        Z_test[:,1] = X_test[:,2] #race column        \n",
    "    elif dataset_name == \"hospital\":\n",
    "        Z_train[:,0] = X_train[:,1] #gender column\n",
    "        Z_train[:,1] = X_train[:,0] #race column\n",
    "\n",
    "        Z_test[:,0] = X_test[:,1] #gender column\n",
    "        Z_test[:,1] = X_test[:,0] #race column \n",
    "    \n",
    "    # Instantiate network\n",
    "    model = utilities.create_nn(dataset_name, X_train[0].shape)\n",
    "    \n",
    "    # Train network \n",
    "    start_time = time.time()\n",
    "    r = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size\n",
    "                   )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "    print(\"Training time for iter \",i,\": \",time_elapsed)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    score = model.evaluate(X_test,Y_test,verbose=0)\n",
    "    model_loss = score[0] \n",
    "    model_acc = score[1]\n",
    "    print(\"Test loss: \",model_loss,\", Test accuracy: \",model_acc)\n",
    "    \n",
    "    fmodel = \"model_wodp_iter{0}.keras\".format(i)\n",
    "    basepath = \"../models/{0}/{1}/{2}/iter{3}/\".format(base_folder,dataset_name,syndataType,i)\n",
    "    \n",
    "    if not os.path.exists(basepath):\n",
    "        os.mkdir(basepath)\n",
    "    \n",
    "    model.save(basepath + fmodel)\n",
    "    savetxt(basepath + 'X_train.csv',X_train,delimiter=',')\n",
    "    savetxt(basepath + 'X_test.csv',X_test,delimiter=',')\n",
    "    savetxt(basepath + 'Y_train.csv',Y_train,delimiter=',')\n",
    "    savetxt(basepath + 'Y_test.csv',Y_test,delimiter=',')\n",
    "    savetxt(basepath + 'Z_train.csv',Z_train,delimiter=',')\n",
    "    savetxt(basepath + 'Z_test.csv',Z_test,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
